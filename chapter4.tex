\chapter{Design and Evauation of Techniques for HPC platforms with SDN-capable Interconnects} In
my research for the disseretation, I propose to solve the challenge of incorporating Software Defined
Networking (SDN) for efficiently running High-Performance Computing (HPC)
applications. SDN is a new paradigm that is successful in other domains, but has not
been fully explored in HPC \cite{kreutz2014software, alalmaei2020sdn, he2016firebird}. 
SDN offers several advantages such as
\begin{itemize}

\item \textbf{Centralized Management :} A controller is responsible for managing the network resources.
\item \textbf{Global View of Network :} The SDN controller receives performance analytics from network resources to learn about the global state of the network.
\item \textbf{Traffic Optimization :} Enables dynamic routing of the traffic based on network condition.
\item \textbf{Programmability :} Programmable interfaces are available for customization of network services.

\end{itemize}
All the above advantages can be applied to the HPC environment. 
The goal of this research is to develop and
evaluate SDN techniques for HPC environments. I focus on these five areas which are (1) flow identification where we identify the types network flows, (2) SDN-enabled flow scheduling where we scheduling the different types of network flows, (3) impact of topology and routing schemes where we evaluate how the flow identification and SDN-enabled flow scheduling performs in state-of-the-art HPC topologies along with their respective routings, (4) SDN-aware communication where we try to evaluate if MPI collective communication algorithms can be changed based on the SDN knowledge about the network, and finally (5) SDN-aware job scheduling where we try to evaluate job placements based on SDN knowledge about the network.




\section{Flow Identification}

%\textcolor{blue}{What is it?}

In the context of SDN, network traffic usually has two kinds of flows. Elephant flows 
carry large amounts of data from a source to a destination. These flows
constitute a bulk of the network traffic and are sensitive to network bandwidth.
Mice flows on the other hand, carry a small amount of data from source to
destination \cite{yang2020flow, afek2015sampling}, and they are latency sensitive. 
Flow identification is classification of network flows into elephant flows or mice flows.
\begin{comment}
For
applications I use, any flow that carries more than a certain threshold of data is an elephant flow, and any other is a
mice flow.
\end{comment}


%\textcolor{blue}{Why you do it?}

By identifying elephant flows, SDN controllers can allocate network resources more 
effectively. The controller, armed with knowledge about these 
bandwidth-intensive flows, can prioritize and allocate appropriate 
links to handle their traffic. This proactive approach helps prevent 
congestion and ensures that critical flows receive sufficient bandwidth, 
leading to improved overall network performance.

%\textcolor{blue}{How to do it?}
To effectively support SDN, we develop and evaluate 
SDN techniques that take these characteristics into 
consideration. Our techniques can be classified into 
two types: those with no extra user information and those with user information.
\subsection{Classifying flows without user information}

First, I propose to use a pure threshold based method, in which elephant flows are 
detected at the edge switches at each polling interval based on 
the amount of data sent. If the amount of data sent is more than the threshold,
then it is an elephant flow. 
\begin{comment}
However, in the HPC environment, depending on applications, 
the time for each iteration may be much less than a second. 
Hence, these existing flow classification schemes will miss many 
iterations of application execution and are not effective for such HPC applications.
\end{comment}
Second, I propose a Deep learning-based scheme, where I try to train a Deep Neural Network(DNN)
which is using the network packets transmision sequence from HPC workloads which are classified
into elephant and mice flows. In this way,
the DNN model is able to recognize the patterns of elephant flows in HPC applications in a 
smaller period of time.

 

\subsection{Classifying flows with user information}
Static communications are communications whose
information can be determined at compile time. In MPI, major portion of
communication is static, that is, it can be determined during compile time. 
For static communications in HPC applications like the ones in Stencil4d 
shown in Figure \ref{Stencil4d Code snippet}, 
the HPC application developer (or compiler and communication library) 
has the knowledge whether a communication is an elephant flow or not. 
If the SDN allows HPC applications (SDN users) to give hints about 
their communications, the flow identification task performed by the 
SDN can be greatly simplified. To facilitate this, we propose to have 
an API for SDN users to provide such information which can help in 
classifying the elephant and the mice flows.
\begin{comment} 
The most complete information about a point-to-point communication i
ncludes the source MPI rank, the destination rank, and the message size. 
Based on the information the users can give the hint when the 
application is loaded (when MPI ranks are mapped to physical nodes).
\end{comment}


%\textcolor{blue}{Significance of results?}

HPC applications deal with massive computations and data transfers, 
needing fast, responsive network connections. When SDN-controllers
pinpoint the types of network flows (such as elephant flows and mice flows) 
these applications generate, it helps to route the bandwidth heavy elephant flows
 through links which are not shared by too many elephant flows, so that each
 of them can get sufficient bandwidth. This reduces the overall congestion 
in the network and the applications run more efficiently.


\begin{figure}[hbtp]
\caption{Stencil4d Code snippet}
\label{code.stencil}
\begin{lstlisting}[breaklines]
for (int i = 0; i < MAX_ITER; i++) {
        MPI_Isend(sendn, 100000000, MPI_CHAR, north, 9, MPI_COMM_WORLD, &reqs[0]
);
        ...
        MPI_Irecv(recvn, 100000000, MPI_CHAR, north, 9, MPI_COMM_WORLD, &reqs[8]
);
        ...
        MPI_Waitall(16, req status);
}
\end{lstlisting}
\end{figure}



\section{SDN-enabled flow scheduling}

%\textcolor{blue}{What is it?}
SDN-enabled flow scheduling builds on top of the previous method 
of flow identification, after the SDN-controller classifies the
network flows as elephant or mice flows, it uses the network state (e.g. network
topology, link loads) and number of elephant flows to generate a routing table 
which can be used to schedule all the elephant flows efficiently. 

%\textcolor{blue}{Why you do it?}
SDN-enabled flow scheduling aims to reduce the network congestion by ensuring that bandwidth
intensive network flows get sufficient bandwidth to transfer their data from source node to 
destination node.

%\textcolor{blue}{How you do it?}
I proposes to develop routing algorithms which aim to load balance the network traffic using the 
global view of a network through the SDN controller.
I propose to develop three algorithms to optimally schedule the elephant flows. I 
try to develop a greedy approach which 
adds the path which is least heavily loaded for routing the elephant flow, an optimal single path routing, which tries to find a non-blocking path for 
every elephant flow in a permutation in a full bisection bandwidth fat-tree. 
and a multipath routing, where the buffer load for k least loaded
paths is analysed, and the one which has the lowest buffer load among the k paths is used to route the elephant flow. 

I then compare how the proposed algorithms perform with respect to other representative routing techiques like static and adaptive routing.

%\textcolor{blue}{Significance of the result}
The significance of this research lies in its development of routing algorithms tailored for Software-Defined Networking (SDN) controllers. By focusing on efficient traffic management, adaptability to changing network conditions, and optimization for high-demand scenarios, this addresses critical challenges in network performance.


\section{Impact of topology and routing schemes}

%\textcolor{blue}{What is it?}

Topology and routing schemes can significantly impact the effectiveness
of SDN for supporting HPC applications. 

%\textcolor{blue}{How to do it?}
I propose to study a number of
widely used interconnect configurations in the HPC environment: fat-tree
with deterministic routing, fat-tree with adaptive routing, and dragonfly.
SDN techniques will be developed and evaluated for
these configurations. 

%\textcolor{blue}{Significance of the result}
The results will give insight about the potential of different 
network architectures in conjunction with SDN to optimize 
performance, scalability, and resource utilization in HPC environments. 
This understanding will not only inform network design decisions but 
also contribute to the development of tailored SDN solutions that 
effectively address the unique challenges posed by high-performance computing workloads.


\section{SDN-aware communication}

%\textcolor{blue}{What is it?}
MPI collective communications, such as MPI All-to-all, 
rely on different algorithms like Recursive Doubling, 
Bruck's Algorithm, and Gather-Scatter Algorithm. 
Each of these algorithms alters the communication behavior inside the application. 
By utilizing the network state information from SDN, SDN-aware communication 
tries to modify these MPI collective algorithms so that they can run efficiently. 

\begin{comment}
\textcolor{blue}{How you do it?}
I select the MPI collective algorithm MPI Allreduce. From the SDN-controller I get the
network topology information and the ranks placement across the network
topology. With this information, I try to select only those ranks in my algorithm
 which needs to make heavy communication as close as possible in the physical network.
I then compare the performance with a regular MPI Allreduce.
\end{comment}
%\textcolor{blue}{Significance of the result}
The results will give insight about the potential of how changing the algorithm 
of an MPI collective according to the information received from SDN can have an effect in 
performance improvement. Moreover, if SDN information can be used for modifying
the MPI collective algorithm, then there can be an efficient algorithm which can work
across a varied set of topologies like fat-tree and dragonfly as long as they have 
SDN support. 



\section{SDN-aware job scheduling}

%\textcolor{blue}{What is it?}
SDN-aware job scheduling uses network and traffic information from
SDN to efficiently map the job ranks to physical nodes on the system 
so that the network has the least congestion when a job runs.

%\textcolor{blue}{How to do it?}

I aim to evelop a job mapping strategy based on the 
flow classification where I incorporated the network flow 
classification done by the API into elephant and mice flows 
to create a job placement such to get the maximum bandwidth possible. 
We compare this new technique with linear and random mapping of ranks to nodes.

%\textcolor{blue}{Significance of the result}

By examining three distinct 
methods - linear mapping, random mapping, and SDN-aware job scheduling - 
the research sheds light on how using information provided by SDN 
job scheduling can help to improve job performance, and minimize
variability, and interference. 

