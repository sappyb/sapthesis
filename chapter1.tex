\chapter{Introduction}

Software Defined Networking (SDN) \cite{kreutz2014software} has emerged as a promising technology and
has been widely implemented across various network environments, including data
centers, campus networks, and wide-area networks. SDN offers several notable
features: (1) a centralized global network view for intelligent traffic and
resource management, (2) flexible per-flow management to accommodate varying
network traffic patterns, (3) network monitoring capabilities providing valuable
traffic statistics, and (4) ease of integrating new network functionalities and
services. These features empower SDN to effectively manage traffic at the flow
level using a centralized view and optimize network resource utilization for
improved performance compared to traditional networking infrastructures \cite{tr2016sdn}.
While these SDN capabilities hold appeal for High-Performance Computing (HPC)
systems and applications, SDN adoption within the HPC domain remains limited.
One reason for this is the absence of clear evidence demonstrating SDN's
superiority over existing networking technologies in high-end HPC systems that
employ sophisticated routing schemes. Existing SDN methodologies are primarily
tailored for internet and data-parallel applications like Hadoop and MapReduce
applications \cite{he2016firebird}, which have communication characteristics different from those
of HPC applications. Consequently, to achieve optimal performance on SDN-based
HPC systems, novel techniques that consider the unique communication patterns of HPC
applications are of utmost importance. 

Large-scale systems aiming to achieve over 1 Exaflop/s of sustained performance have been built.
 Unlike the systems dominating the HPC industry
a decade ago, many of today's and future systems consist of a relatively modest
number of nodes. For instance, Sequoia at LLNL \cite{sequa}, the fastest supercomputer in
the Top500 list in 2012, utilized 96K nodes to achieve 20 Petaflop/s of peak
performance. In comparison, Summit at ORNL \cite{summit}, one of the fastest
supercomputers as of June 2020, employs approximately 4600 nodes but achieves a
peak performance of 200 Petaflop/s. The driving force behind the reduction in the
number of nodes is compute acceleration devices such as GPUs \cite{owens2008gpu}. For example,
an NVIDIA Volta V100 can perform 7 Teraflop/s worth of double-precision
computation compared to 200 Gigaflop/s for a Blue Gene/Q node. However, such a
significant increase in computing capability has not been matched by a similar
increase in network capability. Additionally, the communication performance
achievable by an application on a system remains the major bottleneck for the overall 
application performance.  Therefore, while communication needs tend to expand at a slower
rate compared to computational demands (e.g., analogous to the growth of surface
area versus volume), it remains vital to determine the optimal utilization of
existing communication capabilities and achieve an ideal balance between
computation and communication capabilities.  The central inquiry we aim to
address is whether a system featuring fewer nodes, each possessing greater
computing capability, outperforms a system comprising more nodes, each with
lesser computing capability. 


My dissertation research primarily focuses on the following two areas:

\begin{enumerate} 
\item Developing and evaluating SDN techniques for HPC systems.
I am investigating the influence of SDN on HPC
environments, whether SDN can improve the communication performance for HPC
systems, and whether our proposed techniques result in higher communication
performance in SDN-capable interconnect topologies than existing schemes.
\item Exploring the performance of modern HPC systems across diverse network onfigurations.
I am using end-to-end system simulations to explore the
performance impact of various network design and parameter choices for
GPU-based systems,
conducting a sensitivity study of the overall performance with respect to
 changes in these parameters.  
\end{enumerate} 



The structure of this dissertation aligns with the outlined research
objectives.
Chapter 2 will provide a background on interconnection technologies, 
SDN fundamentals and related works. 
In Chapter 3, I describe the implementation of various SDN-based enhancements in HPC environments and evaluate their impact on application performance. Chapter 4 examines how key network parameters influence modern HPC systems.
Finally, chapter 5 will offer
concluding remarks.

